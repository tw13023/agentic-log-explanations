{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f312cf06",
   "metadata": {},
   "source": [
    "# Phase 1: Pipeline Test\n",
    "\n",
    "Test all modules in the Screener-Reasoner pipeline:\n",
    "1. Data Loader\n",
    "2. Normalizer\n",
    "3. Screener (AllLinLog)\n",
    "4. Evidence Store\n",
    "5. Retriever (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Import all modules\n",
    "from src.data_loader import BGLDataLoader, HDFSDataLoader, Session\n",
    "from src.normalizer import LogNormalizer, get_normalizer\n",
    "from src.screener import Screener, ScreenerOutput\n",
    "from src.evidence_store import EvidenceStore, build_evidence_store\n",
    "from src.retriever import BM25Retriever\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7bfd8",
   "metadata": {},
   "source": [
    "## 1. Test Data Loader (BGL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BGL dataset\n",
    "bgl_loader = BGLDataLoader(\n",
    "    log_file=\"../logs/BGL.log\",\n",
    "    windows_size=10,\n",
    "    step_size=10,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "bgl_loader.load()\n",
    "bgl_loader.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sessions\n",
    "train_sessions = bgl_loader.get_train()\n",
    "test_sessions = bgl_loader.get_test()\n",
    "\n",
    "print(f\"Train sessions: {len(train_sessions)}\")\n",
    "print(f\"Test sessions: {len(test_sessions)}\")\n",
    "\n",
    "# Look at a sample session\n",
    "sample = train_sessions[0]\n",
    "print(f\"\\nSample session: {sample}\")\n",
    "print(f\"\\nFirst 3 log lines:\")\n",
    "for line in sample.lines[:3]:\n",
    "    print(f\"  {line[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9d900",
   "metadata": {},
   "source": [
    "## 2. Test Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BGL normalizer\n",
    "normalizer = get_normalizer(\"BGL\")\n",
    "\n",
    "# Test on a sample session\n",
    "result = normalizer.normalize_session(sample)\n",
    "\n",
    "print(f\"Original length: {result.original_length}\")\n",
    "print(f\"Normalized length: {result.normalized_length}\")\n",
    "print(f\"Compression ratio: {result.compression_ratio:.2%}\")\n",
    "print(f\"\\nParam stats: {result.param_stats}\")\n",
    "print(f\"\\nNormalized text (first 500 chars):\")\n",
    "print(result.normalized_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed72e3",
   "metadata": {},
   "source": [
    "## 3. Test Screener (AllLinLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load screener with pre-trained model\n",
    "screener = Screener(\n",
    "    model_path=\"../best_model/best_model_20250724_072857.pth\",\n",
    "    windows_size=10\n",
    ")\n",
    "\n",
    "screener.load()\n",
    "print(f\"Screener loaded on device: {screener.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e77e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference on a few sessions\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get some normal and anomaly samples\n",
    "normal_samples = [s for s in test_sessions if s.label == 0][:5]\n",
    "anomaly_samples = [s for s in test_sessions if s.label == 1][:5]\n",
    "\n",
    "print(\"Testing on normal samples:\")\n",
    "for s in normal_samples:\n",
    "    output = screener.predict(s)\n",
    "    status = \"✓\" if output.pred == 0 else \"✗\"\n",
    "    print(f\"  {s.session_id}: pred={output.pred}, prob={output.anomaly_prob:.4f}, margin={output.margin:.4f} {status}\")\n",
    "\n",
    "print(\"\\nTesting on anomaly samples:\")\n",
    "for s in anomaly_samples:\n",
    "    output = screener.predict(s)\n",
    "    status = \"✓\" if output.pred == 1 else \"✗\"\n",
    "    print(f\"  {s.session_id}: pred={output.pred}, prob={output.anomaly_prob:.4f}, margin={output.margin:.4f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f3f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full evaluation on test set\n",
    "print(\"Running full evaluation on test set...\")\n",
    "metrics = screener.evaluate(test_sessions)\n",
    "\n",
    "print(f\"\\n=== Test Set Metrics ===\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f82d0",
   "metadata": {},
   "source": [
    "## 4. Test Evidence Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ab23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build evidence store from train sessions\n",
    "evidence_store = EvidenceStore(dataset=\"BGL\")\n",
    "evidence_store.build_from_sessions(train_sessions)\n",
    "\n",
    "# Print stats\n",
    "stats = evidence_store.stats()\n",
    "print(f\"\\n=== Evidence Store Stats ===\")\n",
    "for k, v in stats.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a58a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evidence store for later use\n",
    "evidence_store.save(\"../results/evidence_store_BGL.json\")\n",
    "\n",
    "# Sample evidence document\n",
    "sample_doc = evidence_store[0]\n",
    "print(f\"\\nSample evidence document:\")\n",
    "print(f\"  ID: {sample_doc.evidence_id}\")\n",
    "print(f\"  Session: {sample_doc.session_id}\")\n",
    "print(f\"  Label: {sample_doc.metadata.get('label')}\")\n",
    "print(f\"  Text (first 300 chars): {sample_doc.text[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11940b4f",
   "metadata": {},
   "source": [
    "## 5. Test BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BM25 retriever\n",
    "retriever = BM25Retriever(evidence_store)\n",
    "retriever.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval for an anomaly session\n",
    "test_anomaly = [s for s in test_sessions if s.label == 1][0]\n",
    "\n",
    "print(f\"Query session: {test_anomaly.session_id}\")\n",
    "print(f\"Query label: {test_anomaly.label}\")\n",
    "print(f\"\\nQuery log lines:\")\n",
    "for line in test_anomaly.lines[:3]:\n",
    "    print(f\"  {line[:80]}...\")\n",
    "\n",
    "# Retrieve top-5 evidence\n",
    "hits = retriever.retrieve_for_session(test_anomaly, top_k=5)\n",
    "\n",
    "print(f\"\\n=== Top-5 Retrieved Evidence ===\")\n",
    "for hit in hits:\n",
    "    label = hit.metadata.get('label', 'unknown')\n",
    "    label_str = \"ANOMALY\" if label == 1 else \"NORMAL\"\n",
    "    print(f\"\\n[{hit.rank}] {hit.evidence_id} (score={hit.score:.4f}, label={label_str})\")\n",
    "    print(f\"    {hit.text[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45061908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze retrieval quality: what fraction of top-k are same-label?\n",
    "from collections import Counter\n",
    "\n",
    "# Sample 20 anomaly sessions\n",
    "test_anomalies = [s for s in test_sessions if s.label == 1][:20]\n",
    "\n",
    "same_label_counts = []\n",
    "for session in test_anomalies:\n",
    "    hits = retriever.retrieve_for_session(session, top_k=5)\n",
    "    same_label = sum(1 for h in hits if h.metadata.get('label') == session.label)\n",
    "    same_label_counts.append(same_label)\n",
    "\n",
    "avg_same_label = sum(same_label_counts) / len(same_label_counts)\n",
    "print(f\"Average same-label hits in top-5: {avg_same_label:.2f} / 5 ({avg_same_label/5:.1%})\")\n",
    "print(f\"Distribution: {Counter(same_label_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146fbcd",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Phase 1 modules are working:\n",
    "- ✅ Data Loader (BGL sessions)\n",
    "- ✅ Normalizer (IP, HEX, etc. → placeholders)\n",
    "- ✅ Screener (AllLinLog inference)\n",
    "- ✅ Evidence Store (train corpus)\n",
    "- ✅ BM25 Retriever (top-k evidence)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
