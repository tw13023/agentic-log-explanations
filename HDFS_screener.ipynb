{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d05ffed",
   "metadata": {},
   "source": [
    "# HDFS Anomaly Detection Screener\n",
    "\n",
    "This notebook loads the pre-trained AllLinLog model and runs inference on the HDFS test set for anomaly screening.\n",
    "\n",
    "## Requirements\n",
    "- `torch`\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `scikit-learn`\n",
    "- `tqdm`\n",
    "- `tiktoken`\n",
    "- `linformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2642910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from linformer import Linformer\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "LOG_FILE = \"./logs/HDFS.log\"\n",
    "LABEL_FILE = \"./logs/anomaly_label_HDFS.csv\"\n",
    "MODEL_PATH = \"./best_model_HDFS/best_model_HDFS20250804_201746.pth\"\n",
    "WINDOW = 'session'  # HDFS uses session-based windowing\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "SEED = 42\n",
    "BATCH_SIZE = 8\n",
    "MAX_TOKEN_LENGTH = 18000  # Will be updated after data loading\n",
    "\n",
    "# Model hyperparameters (must match training)\n",
    "CL100K_VOCAB_SIZE = 100264  # GPT4 BPE\n",
    "EMBEDDING_DIM = 128\n",
    "FF_HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 1\n",
    "NUM_HEADS = 4\n",
    "K = 32  # Linformer projection dimension\n",
    "DROPOUT = 0.5\n",
    "MAX_SEGMENT_LENGTHS = 298  # Must match trained model checkpoint\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set to {seed}\")\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba553543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class LogDataset(Dataset):\n",
    "    def __init__(self, sessions):\n",
    "        self.sessions = sessions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sessions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        session = self.sessions[idx]\n",
    "        return {\n",
    "            'input_ids': session['input_ids'],\n",
    "            'segment_ids': session['segment_ids'],\n",
    "            'session_label': session['session_label']\n",
    "        }\n",
    "\n",
    "\n",
    "def load_gpt4_tokenizer():\n",
    "    \"\"\"Load the GPT-4 BPE tokenizer.\"\"\"\n",
    "    print(\"Loading cl100k_base (GPT-4) tokenizer...\")\n",
    "    return tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "\n",
    "def tokenize_and_construct_input(log_sequence, tokenizer, max_len=18000):\n",
    "    \"\"\"Tokenize log messages and construct input IDs and segment IDs.\"\"\"\n",
    "    input_ids = []\n",
    "    segment_ids = []\n",
    "\n",
    "    allowed_special = {\"<|startoftext|>\", \"<|endoftext|>\"}\n",
    "    bos_token = tokenizer.encode(\"<|startoftext|>\", allowed_special=allowed_special)[0]\n",
    "    eos_token = tokenizer.encode(\"<|endoftext|>\", allowed_special=allowed_special)[0]\n",
    "\n",
    "    for i, log in enumerate(log_sequence):\n",
    "        tokens = tokenizer.encode(log, allowed_special=allowed_special)\n",
    "        if i == 0:\n",
    "            tokens = [bos_token] + tokens\n",
    "        tokens = tokens + [eos_token]\n",
    "        input_ids.extend(tokens)\n",
    "        segment_ids.extend([i] * len(tokens))\n",
    "\n",
    "    if len(input_ids) > max_len:\n",
    "        input_ids = input_ids[:max_len]\n",
    "        segment_ids = segment_ids[:max_len]\n",
    "\n",
    "    return input_ids, segment_ids\n",
    "\n",
    "\n",
    "def create_sessions_with_segment_ids(log_data, tokenizer, label_file=None, max_len=18000):\n",
    "    \"\"\"Process HDFS log data into sessions grouped by block ID.\"\"\"\n",
    "    # Group logs by block ID\n",
    "    session_dict = {}\n",
    "    for line in tqdm(log_data, desc=\"Grouping logs by session\"):\n",
    "        tokens = line.split()\n",
    "        if len(tokens) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            timestamp_str = \" \".join(tokens[:2])\n",
    "            timestamp = datetime.strptime(timestamp_str, '%y%m%d %H%M%S').timestamp()\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        blk_ids = list(set(re.findall(r'(blk_-?\\d+)', line)))\n",
    "        if len(blk_ids) != 1:\n",
    "            continue\n",
    "        blk_id = blk_ids[0]\n",
    "\n",
    "        if blk_id not in session_dict:\n",
    "            session_dict[blk_id] = []\n",
    "        session_dict[blk_id].append((timestamp, line))\n",
    "\n",
    "    # Load label mapping if provided\n",
    "    label_mapping = {}\n",
    "    if label_file:\n",
    "        label_df = pd.read_csv(label_file, engine='c', na_filter=False)\n",
    "        label_df = label_df.set_index(\"BlockId\")\n",
    "        label_mapping = label_df[\"Label\"].to_dict()\n",
    "\n",
    "    sessions = []\n",
    "    for blk_id, events in tqdm(session_dict.items(), desc=\"Processing sessions\"):\n",
    "        events.sort(key=lambda x: x[0])\n",
    "        log_sequence = [msg for (ts, msg) in events]\n",
    "        if label_file:\n",
    "            session_label = 1 if label_mapping.get(blk_id, \"Normal\") == \"Anomaly\" else 0\n",
    "        else:\n",
    "            session_label = 0\n",
    "        input_ids, segment_ids = tokenize_and_construct_input(log_sequence, tokenizer, max_len)\n",
    "        sessions.append({\n",
    "            \"block_id\": blk_id,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"segment_ids\": segment_ids,\n",
    "            \"session_label\": session_label\n",
    "        })\n",
    "\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea7bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, segment_vocab_size, embedding_dim=128):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.segment_embedding = nn.Embedding(segment_vocab_size, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, embedding_dim)\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, position_ids=None):\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(input_ids.size(1), device=input_ids.device).unsqueeze(0).repeat(input_ids.size(0), 1)\n",
    "        E_token = self.token_embedding(input_ids)\n",
    "        E_segment = self.segment_embedding(segment_ids)\n",
    "        E_position = self.position_embedding(position_ids)\n",
    "        return E_token + E_segment + E_position\n",
    "\n",
    "\n",
    "class LinformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embedding_dim, seq_len, num_heads=2, ff_hidden_dim=128, k=128, dropout=0.1):\n",
    "        super(LinformerEncoderLayer, self).__init__()\n",
    "        self.self_attention = Linformer(\n",
    "            dim=embedding_dim,\n",
    "            seq_len=int(seq_len),\n",
    "            depth=1,\n",
    "            heads=num_heads,\n",
    "            k=k,\n",
    "            one_kv_head=True,\n",
    "            share_kv=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, ff_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_dim, embedding_dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_output = self.self_attention(x)\n",
    "        x = self.norm1(x + self.dropout(attention_output))\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinformerTransformerEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, embedding_dim, seq_len, num_heads=2, ff_hidden_dim=128, k=128, dropout=0.1):\n",
    "        super(LinformerTransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            LinformerEncoderLayer(embedding_dim, seq_len, num_heads, ff_hidden_dim, k, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AllLinLog(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, segment_vocab_size, embedding_dim=128,\n",
    "                 num_layers=1, num_heads=2, ff_hidden_dim=128, k=128, num_classes=2, dropout=0.1, max_segment_lengths=100):\n",
    "        super(AllLinLog, self).__init__()\n",
    "        self.embedding_layer = EmbeddingLayer(vocab_size, max_seq_len, segment_vocab_size=max_segment_lengths, embedding_dim=embedding_dim)\n",
    "        self.encoder = LinformerTransformerEncoder(num_layers, embedding_dim, max_seq_len, num_heads, ff_hidden_dim, k, dropout)\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, position_ids, attention_mask=None):\n",
    "        embeddings = self.embedding_layer(input_ids, segment_ids, position_ids)\n",
    "        encoder_output = self.encoder(embeddings)\n",
    "        pooled_output = torch.mean(encoder_output, dim=1)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b26409d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading logs from: ./logs/HDFS.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Logs: 11175629it [00:04, 2713327.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11175629 logs in 4.12 seconds.\n",
      "Loading cl100k_base (GPT-4) tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grouping logs by session: 100%|██████████| 11175629/11175629 [00:54<00:00, 205719.94it/s]\n",
      "Processing sessions: 100%|██████████| 575061/575061 [03:14<00:00, 2960.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens in sessions: 15166\n",
      "Number of sessions: 575061\n",
      "\n",
      "Dataset Split:\n",
      "Train sessions: 402542 | Val sessions: 86259 | Test sessions: 86260\n",
      "\n",
      "Test set => Normal: 83734 | Anomalous: 2526\n",
      "Anomalous ratio: 2.93%\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data (same split as training for reproducibility)\n",
    "print(\"Loading logs from:\", LOG_FILE)\n",
    "start_time = time.time()\n",
    "\n",
    "with open(LOG_FILE, mode=\"r\", encoding='utf8') as f:\n",
    "    logs = [x.strip() for x in tqdm(f, desc=\"Reading Logs\")]\n",
    "\n",
    "print(f\"Loaded {len(logs)} logs in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "tokenizer = load_gpt4_tokenizer()\n",
    "all_sessions = create_sessions_with_segment_ids(logs, tokenizer, label_file=LABEL_FILE, max_len=MAX_TOKEN_LENGTH)\n",
    "\n",
    "# Calculate max token length\n",
    "token_lengths = [len(session[\"input_ids\"]) for session in all_sessions]\n",
    "MAX_TOKEN_LENGTH = max(token_lengths)\n",
    "print(f\"Max tokens in sessions: {MAX_TOKEN_LENGTH}\")\n",
    "print(f\"Number of sessions: {len(all_sessions)}\")\n",
    "\n",
    "# Perform the same stratified split as training\n",
    "session_labels = [s[\"session_label\"] for s in all_sessions]\n",
    "\n",
    "# First split: train and temp (val+test)\n",
    "train_sessions, temp_sessions, train_labels, temp_labels = train_test_split(\n",
    "    all_sessions,\n",
    "    session_labels,\n",
    "    test_size=(1 - TRAIN_RATIO),\n",
    "    stratify=session_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: val and test\n",
    "val_relative = VAL_RATIO / (VAL_RATIO + TEST_RATIO)\n",
    "temp_labels = [s[\"session_label\"] for s in temp_sessions]\n",
    "val_sessions, test_sessions, val_labels, test_labels = train_test_split(\n",
    "    temp_sessions,\n",
    "    temp_labels,\n",
    "    test_size=(1 - val_relative),\n",
    "    stratify=temp_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"Train sessions: {len(train_sessions)} | Val sessions: {len(val_sessions)} | Test sessions: {len(test_sessions)}\")\n",
    "\n",
    "# Test set statistics\n",
    "test_normal = sum(s['session_label'] == 0 for s in test_sessions)\n",
    "test_anomalous = sum(s['session_label'] == 1 for s in test_sessions)\n",
    "print(f\"\\nTest set => Normal: {test_normal} | Anomalous: {test_anomalous}\")\n",
    "print(f\"Anomalous ratio: {test_anomalous/(test_anomalous + test_normal):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee89c20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b50b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataLoader created with 10783 batches\n"
     ]
    }
   ],
   "source": [
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item[\"input_ids\"], dtype=torch.long) for item in batch]\n",
    "    segment_ids = [torch.tensor(item[\"segment_ids\"], dtype=torch.long) for item in batch]\n",
    "    session_labels = torch.tensor([item[\"session_label\"] for item in batch], dtype=torch.long)\n",
    "\n",
    "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    padded_segment_ids = pad_sequence(segment_ids, batch_first=True, padding_value=0)\n",
    "\n",
    "    padded_input_ids = padded_input_ids[:, :MAX_TOKEN_LENGTH]\n",
    "    padded_segment_ids = padded_segment_ids[:, :MAX_TOKEN_LENGTH]\n",
    "\n",
    "    # Clamp segment_ids to valid range for embedding\n",
    "    padded_segment_ids = torch.clamp(padded_segment_ids, 0, MAX_SEGMENT_LENGTHS - 1)\n",
    "\n",
    "    attention_masks = (padded_input_ids != 0).long()\n",
    "\n",
    "    return padded_input_ids, padded_segment_ids, attention_masks, session_labels\n",
    "\n",
    "\n",
    "# Create test dataloader\n",
    "test_dataset = LogDataset(test_sessions)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Test DataLoader created with {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cf0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: ./best_model_HDFS/best_model_HDFS20250804_201746.pth\n",
      "Model loaded successfully!\n",
      "Total parameters: 15,501,506\n",
      "Model size: 59.13 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "print(f\"Loading model from: {MODEL_PATH}\")\n",
    "\n",
    "model = AllLinLog(\n",
    "    vocab_size=CL100K_VOCAB_SIZE,\n",
    "    max_seq_len=MAX_TOKEN_LENGTH,\n",
    "    segment_vocab_size=MAX_SEGMENT_LENGTHS,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    ff_hidden_dim=FF_HIDDEN_DIM,\n",
    "    k=K,\n",
    "    num_classes=2,\n",
    "    dropout=DROPOUT,\n",
    "    max_segment_lengths=MAX_SEGMENT_LENGTHS\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b588cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RUNNING INFERENCE ON TEST SET\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 10783/10783 [00:28<00:00, 376.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set\n",
    "def evaluate_test_set(model, test_loader, device):\n",
    "    \"\"\"Evaluate the model on the test set and return predictions.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Running Inference\"):\n",
    "            input_ids, segment_ids, attention_masks, labels = [b.to(device) for b in batch]\n",
    "            logits = model(input_ids, segment_ids, position_ids=None, attention_mask=attention_masks)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING INFERENCE ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "predictions, labels, probabilities = evaluate_test_set(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4068bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal    0.99952   0.99992   0.99972     83734\n",
      "   Anomalous    0.99719   0.98416   0.99064      2526\n",
      "\n",
      "    accuracy                        0.99946     86260\n",
      "   macro avg    0.99836   0.99204   0.99518     86260\n",
      "weighted avg    0.99945   0.99946   0.99945     86260\n",
      "\n",
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX\n",
      "============================================================\n",
      "           Pred_Normal  Pred_Anomalous\n",
      "Normal           83727               7\n",
      "Anomalous           40            2486\n",
      "\n",
      "============================================================\n",
      "SUMMARY METRICS\n",
      "============================================================\n",
      "Accuracy: 0.9995\n",
      "True Positives (Anomalies detected): 2486\n",
      "True Negatives (Normal correctly identified): 83727\n",
      "False Positives (False alarms): 7\n",
      "False Negatives (Missed anomalies): 40\n"
     ]
    }
   ],
   "source": [
    "# Generate and display results\n",
    "target_names = [\"Normal\", \"Anomalous\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(labels, predictions, target_names=target_names, digits=5))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=[f\"Pred_{n}\" for n in target_names])\n",
    "print(cm_df)\n",
    "\n",
    "# Calculate key metrics\n",
    "accuracy = (predictions == labels).mean()\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"True Positives (Anomalies detected): {tp}\")\n",
    "print(f\"True Negatives (Normal correctly identified): {tn}\")\n",
    "print(f\"False Positives (False alarms): {fp}\")\n",
    "print(f\"False Negatives (Missed anomalies): {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf6aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Screener function ready!\n",
      "Usage: result = screen_hdfs_logs(log_messages_list, model, tokenizer, device)\n"
     ]
    }
   ],
   "source": [
    "# Screener function for new HDFS log sessions\n",
    "def screen_hdfs_logs(log_messages, model, tokenizer, device, max_len=18000, max_segment=298):\n",
    "    \"\"\"\n",
    "    Screen a sequence of HDFS log messages for anomalies.\n",
    "    \n",
    "    Args:\n",
    "        log_messages: List of log message strings (from one block/session)\n",
    "        model: Trained AllLinLog model\n",
    "        tokenizer: GPT-4 tokenizer\n",
    "        device: torch device\n",
    "        max_len: Maximum token length (for truncation only)\n",
    "        max_segment: Maximum segment ID for embedding\n",
    "    \n",
    "    Returns:\n",
    "        dict with prediction, probability, and confidence\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    input_ids, segment_ids = tokenize_and_construct_input(log_messages, tokenizer, max_len)\n",
    "    \n",
    "    # Clamp segment_ids to valid range\n",
    "    segment_ids = [min(s, max_segment - 1) for s in segment_ids]\n",
    "    \n",
    "    # Convert to tensors - DO NOT pad to max_len (causes signal dilution in mean pooling)\n",
    "    input_ids_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "    segment_ids_tensor = torch.tensor([segment_ids], dtype=torch.long).to(device)\n",
    "    \n",
    "    attention_mask = (input_ids_tensor != 0).long()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids_tensor, segment_ids_tensor, position_ids=None, attention_mask=attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": \"Anomalous\" if pred == 1 else \"Normal\",\n",
    "        \"anomaly_probability\": probs[0, 1].item(),\n",
    "        \"normal_probability\": probs[0, 0].item(),\n",
    "        \"confidence\": probs[0, pred].item(),\n",
    "        \"sequence_length\": len(input_ids)\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nScreener function ready!\")\n",
    "print(\"Usage: result = screen_hdfs_logs(log_messages_list, model, tokenizer, device)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d504cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMO: Screening sample sessions from test set\n",
      "============================================================\n",
      "\n",
      "Sample 1 (Block: blk_-7247421860583020514): Actual=Normal, Predicted=Normal ✓\n",
      "  Anomaly probability: 0.0000\n",
      "  Sequence length: 904 tokens\n",
      "\n",
      "Sample 2 (Block: blk_4609193020729643794): Actual=Normal, Predicted=Normal ✓\n",
      "  Anomaly probability: 0.0000\n",
      "  Sequence length: 904 tokens\n",
      "\n",
      "Sample 3 (Block: blk_-7082627475978321318): Actual=Anomalous, Predicted=Anomalous ✓\n",
      "  Anomaly probability: 1.0000\n",
      "  Sequence length: 213 tokens\n",
      "\n",
      "Sample 4 (Block: blk_-221433238572346863): Actual=Anomalous, Predicted=Anomalous ✓\n",
      "  Anomaly probability: 1.0000\n",
      "  Sequence length: 701 tokens\n"
     ]
    }
   ],
   "source": [
    "# Demo: Screen sample sessions from test set\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEMO: Screening sample sessions from test set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get a few samples (normal and anomalous)\n",
    "normal_samples = [s for s in test_sessions if s[\"session_label\"] == 0][:2]\n",
    "anomalous_samples = [s for s in test_sessions if s[\"session_label\"] == 1][11:13]\n",
    "\n",
    "for i, sample in enumerate(normal_samples + anomalous_samples):\n",
    "    actual = \"Normal\" if sample[\"session_label\"] == 0 else \"Anomalous\"\n",
    "    block_id = sample.get(\"block_id\", \"Unknown\")\n",
    "    \n",
    "    # Process through model - DO NOT pad to MAX_TOKEN_LENGTH\n",
    "    # Just use the actual sequence length (matching DataLoader behavior)\n",
    "    input_ids = torch.tensor([sample[\"input_ids\"]], dtype=torch.long).to(device)\n",
    "    segment_ids = torch.tensor([sample[\"segment_ids\"]], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Clamp segment_ids\n",
    "    segment_ids = torch.clamp(segment_ids, 0, MAX_SEGMENT_LENGTHS - 1)\n",
    "    \n",
    "    attention_mask = (input_ids != 0).long()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, position_ids=None, attention_mask=attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        pred = \"Anomalous\" if logits.argmax(dim=1).item() == 1 else \"Normal\"\n",
    "    \n",
    "    status = \"✓\" if pred == actual else \"✗\"\n",
    "    print(f\"\\nSample {i+1} (Block: {block_id}): Actual={actual}, Predicted={pred} {status}\")\n",
    "    print(f\"  Anomaly probability: {probs[0, 1].item():.4f}\")\n",
    "    print(f\"  Sequence length: {len(sample['input_ids'])} tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
